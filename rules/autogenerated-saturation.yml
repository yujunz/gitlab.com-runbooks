# WARNING. DO NOT EDIT THIS FILE BY HAND. USE ./rules-jsonnet/saturation.jsonnet TO GENERATE IT
# YOUR CHANGES WILL BE OVERRIDDEN
groups:
- name: Saturation Rules (autogenerated)
  interval: 1m
  rules:
  - record: gitlab_component_saturation:ratio
    labels:
      component: cgroup_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", environment!="",type=~"gitaly|praefect"} -
              container_memory_cache{id="/system.slice/gitlab-runsvdir.service", environment!="",type=~"gitaly|praefect"} -
              container_memory_swap{id="/system.slice/gitlab-runsvdir.service", environment!="",type=~"gitaly|praefect"}
            )
            /
            container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", environment!="",type=~"gitaly|praefect"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - avg by (environment, tier, type, stage) (
              rate(node_cpu_seconds_total{mode="idle", environment!="",type!="",type!~"waf|console-node|deploy-node"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_inodes
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - (
              node_filesystem_files_free{fstype=~"(ext.|xfs)", environment!="",type!="",type!~"waf|bastion"}
              /
              node_filesystem_files{fstype=~"(ext.|xfs)", environment!="",type!="",type!~"waf|bastion"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              1 - instance:node_filesystem_avail:ratio{fstype=~"ext.|xfs", environment!="",type!="",type!~"waf|bastion"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_iops
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_reads_completed_total{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}[20m])
            /
            node_disk_max_read_iops{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_throughput
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_read_bytes_total{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}[20m])
            /
            node_disk_max_read_bytes_seconds{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_iops
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_writes_completed_total{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}[20m])
            /
            node_disk_max_write_iops{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_throughput
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            rate(node_disk_written_bytes_total{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}[20m])
            /
            node_disk_max_write_bytes_seconds{device!="sda", environment!="",type=~"patroni|gitaly|nfs"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg by (environment, tier, type, stage) (
              avg_over_time(elasticsearch_process_cpu_percent{environment!="",type=~"logging|search"}[1m]) / 100
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_disk_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage) (
              (elasticsearch_filesystem_data_size_bytes{environment!="",type=~"logging|search"} - elasticsearch_filesystem_data_free_bytes{environment!="",type=~"logging|search"})
            )
            /
            sum by (environment, tier, type, stage) (
              elasticsearch_filesystem_data_size_bytes{environment!="",type=~"logging|search"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_jvm_heap_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            elasticsearch_jvm_memory_used_bytes{area="heap", environment!="",type=~"logging|search"}
            /
            elasticsearch_jvm_memory_max_bytes{area="heap", environment!="",type=~"logging|search"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg_over_time(elasticsearch_process_cpu_percent{environment!="",type=~"logging|search"}[5m]) / 100
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_disk_space
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              (
                elasticsearch_filesystem_data_size_bytes{environment!="",type=~"logging|search"}
                -
                elasticsearch_filesystem_data_free_bytes{environment!="",type=~"logging|search"}
              )
              /
              elasticsearch_filesystem_data_size_bytes{environment!="",type=~"logging|search"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: elastic_thread_pools
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(elasticsearch_thread_pool_active_count{exported_type!="snapshot", environment!="",type=~"logging|search"}[5m])
              /
              (avg_over_time(elasticsearch_thread_pool_threads_count{exported_type!="snapshot", environment!="",type=~"logging|search"}[5m]) > 0)
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: go_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, fqdn) (
              go_memstats_alloc_bytes{environment!="",type=~"gitaly|web-pages|monitoring|web|praefect|registry|api"}
            )
            /
            sum by (environment, tier, type, stage, fqdn) (
              node_memory_MemTotal_bytes{environment!="",type=~"gitaly|web-pages|monitoring|web|praefect|registry|api"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_hpa_instances
      stage: main
      tier: inf
      type: kube
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            label_replace(
              label_replace(
                kube_hpa_status_desired_replicas{environment!="", hpa!~"gitlab-sidekiq-(database-throttled|elasticsearch|gitaly-throttled|memory-bound|urgent-other)-v1"}
                /
                kube_hpa_spec_max_replicas,
                "stage", "cny", "hpa", "gitlab-cny-.*"
              ),
              "type", "$1", "hpa", "gitlab-(?:cny-)?(\\w+)"
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_disk_space
      stage: main
      tier: inf
      type: kube
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            kubelet_volume_stats_used_bytes
            /
            kubelet_volume_stats_capacity_bytes
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_inodes
      stage: main
      tier: inf
      type: kube
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            kubelet_volume_stats_inodes_used
            /
            kubelet_volume_stats_inodes
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            instance:node_memory_utilization:ratio{environment!="",type!="",type!~"waf|monitoring"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: open_fds
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              process_open_fds{environment!="",type!="",type!~"waf"}
              /
              process_max_fds{environment!="",type!="",type!~"waf"}
            )
            or
            (
              ruby_file_descriptors{environment!="",type!="",type!~"waf"}
              /
              ruby_process_max_fds{environment!="",type!="",type!~"waf"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_primary
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without (state) (
              pg_stat_activity_count{datname="gitlabhq_production", state!="idle", environment!="",type="patroni"} unless on(instance) (pg_replication_is_replica == 1)
            )
            / on (environment, tier, type, stage, fqdn)
            pg_settings_max_connections{environment!="",type="patroni"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_replica
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without (state) (
              pg_stat_activity_count{datname="gitlabhq_production", state!="idle", environment!="",type="patroni"} and on(instance) (pg_replication_is_replica == 1)
            )
            / on (environment, tier, type, stage, fqdn)
            pg_settings_max_connections{environment!="",type="patroni"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_primary_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment!="",type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment!="",type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment!="",type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment!="",type="pgbouncer"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", environment!="",type="pgbouncer"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_single_core
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without(cpu, mode) (
              rate(
                namedprocess_namegroup_cpu_seconds_total{groupname=~"pgbouncer.*", environment!="",type=~"pgbouncer|patroni"}[1m]
              )
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_primary_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", environment!="",type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", environment!="",type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", environment!="",type="pgbouncer"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", environment!="",type="pgbouncer"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", environment!="",type="pgbouncer"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_replica_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", environment!="",type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", environment!="",type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", environment!="",type="patroni"}[5m]) +
              avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", environment!="",type="patroni"}[5m])
            )
            / on(environment, tier, type, stage, fqdn, instance) group_left()
            sum by (environment, tier, type, stage, fqdn, instance) (
              avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", environment!="",type="patroni"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: private_runners
      stage: main
      tier: runners
      type: ci-runners
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state) (max_over_time(gitlab_runner_jobs{job="private-runners"}[1m]))
            /
            gitlab_runner_limit{job="private-runners"} > 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: rails_db_connection_pool
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              avg_over_time(gitlab_database_connection_pool_busy{class="ActiveRecord::Base", environment!="",type=~"web|api|git|sidekiq"}[5m])
              +
              avg_over_time(gitlab_database_connection_pool_dead{class="ActiveRecord::Base", environment!="",type=~"web|api|git|sidekiq"}[5m])
            )
            /
            gitlab_database_connection_pool_size{class="ActiveRecord::Base", environment!="",type=~"web|api|git|sidekiq"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_clients
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max_over_time(redis_connected_clients{environment!="",type=~"redis|redis-sidekiq|redis-cache"}[1m])
            /
            redis_config_maxclients{environment!="",type=~"redis|redis-sidekiq|redis-cache"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_memory
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            max by (environment, tier, type, stage, fqdn) (
              label_replace(redis_memory_used_rss_bytes{environment!="",type=~"redis|redis-sidekiq|redis-cache"}, "memtype", "rss","","")
              or
              label_replace(redis_memory_used_bytes{environment!="",type=~"redis|redis-sidekiq|redis-cache"}, "memtype", "used","","")
            )
            /
            avg by (environment, tier, type, stage, fqdn) (
              node_memory_MemTotal_bytes{environment!="",type=~"redis|redis-sidekiq|redis-cache"}
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_primary_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              rate(redis_cpu_user_seconds_total{environment!="",type=~"redis|redis-sidekiq|redis-cache"}[1m])
              +
              rate(redis_cpu_sys_seconds_total{environment!="",type=~"redis|redis-sidekiq|redis-cache"}[1m])
            )
            and on (instance) redis_instance_info{role="master"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: redis_secondary_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            (
              rate(redis_cpu_user_seconds_total{environment!="",type=~"redis|redis-sidekiq|redis-cache"}[1m])
              +
              rate(redis_cpu_sys_seconds_total{environment!="",type=~"redis|redis-sidekiq|redis-cache"}[1m])
            )
            and on (instance) redis_instance_info{role!="master"}
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: shard_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            1 - avg by (environment, tier, type, stage, shard) (
              rate(node_cpu_seconds_total{mode="idle", environment!="",type!="",type!~"waf|console-node|deploy-node"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: shared_runners
      stage: main
      tier: runners
      type: ci-runners
    expr: |
      max by(environment) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state) (max_over_time(gitlab_runner_jobs{job="shared-runners"}[1m]))
            /
            gitlab_runner_limit{job="shared-runners"} > 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: shared_runners_gitlab
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum without(executor_stage, exported_stage, state) (max_over_time(gitlab_runner_jobs{job="shared-runners-gitlab-org"}[1m]))
            /
            gitlab_runner_limit{job="shared-runners-gitlab-org"} > 0
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: sidekiq_shard_workers
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by (environment, tier, type, stage, shard) (
              avg_over_time(sidekiq_running_jobs{shard!~"database-throttled|elasticsearch|gitaly-throttled|memory-bound", environment!="",type="sidekiq"}[5m])
            )
            /
            sum by (environment, tier, type, stage, shard) (
              avg_over_time(sidekiq_concurrency{shard!~"database-throttled|elasticsearch|gitaly-throttled|memory-bound", environment!="",type="sidekiq"}[5m])
            )
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: single_node_cpu
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", environment!="",type!="",type!~"waf|console-node|deploy-node"}[5m]))
            ,
            1)
        ,
        0)
      )
  - record: gitlab_component_saturation:ratio
    labels:
      component: single_node_puma_workers
    expr: |
      max by(environment, tier, type, stage) (
        clamp_min(
          clamp_max(
            sum by(environment, tier, type, stage, fqdn) (avg_over_time(puma_active_connections{environment!="",type=~"web|api|git|sidekiq"}[1m]))
            /
            sum by(environment, tier, type, stage, fqdn) (puma_max_threads{pid="puma_master", environment!="",type=~"web|api|git|sidekiq"})
            ,
            1)
        ,
        0)
      )
- name: GitLab Component Saturation Max SLOs
  interval: 5m
  rules:
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: cgroup_memory
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: cgroup_memory
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: cpu
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: cpu
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_inodes
    expr: '0.75'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_inodes
    expr: '0.8'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_space
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_space
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_iops
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_iops
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_throughput
    expr: '0.7'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_read_throughput
    expr: '0.8'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_iops
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_iops
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_throughput
    expr: '0.7'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: disk_sustained_write_throughput
    expr: '0.8'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_cpu
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_cpu
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_disk_space
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_disk_space
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_jvm_heap_memory
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_jvm_heap_memory
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_cpu
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_cpu
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_disk_space
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_single_node_disk_space
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: elastic_thread_pools
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: elastic_thread_pools
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: go_memory
    expr: '0.9'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: go_memory
    expr: '0.98'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_hpa_instances
    expr: '0.95'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_hpa_instances
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_disk_space
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_disk_space
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_inodes
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: kube_persistent_volume_claim_inodes
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: memory
    expr: '0.9'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: memory
    expr: '0.98'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: open_fds
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: open_fds
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_primary
    expr: '0.7'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_primary
    expr: '0.8'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_replica
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pg_active_db_connections_replica
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_primary_pool
    expr: '0.9'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_async_primary_pool
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_single_core
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_single_core
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_primary_pool
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_primary_pool
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_replica_pool
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: pgbouncer_sync_replica_pool
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: private_runners
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: private_runners
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: rails_db_connection_pool
    expr: '0.9'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: rails_db_connection_pool
    expr: '0.99'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_clients
    expr: '0.8'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_clients
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_memory
    expr: '0.65'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_memory
    expr: '0.75'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_primary_cpu
    expr: '0.7'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_primary_cpu
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: redis_secondary_cpu
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: redis_secondary_cpu
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: shard_cpu
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: shard_cpu
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: shared_runners
    expr: '0.9'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: shared_runners
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: shared_runners_gitlab
    expr: '0.9'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: shared_runners_gitlab
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: sidekiq_shard_workers
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: sidekiq_shard_workers
    expr: '0.9'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: single_node_cpu
    expr: '0.9'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: single_node_cpu
    expr: '0.95'
  - record: slo:max:soft:gitlab_component_saturation:ratio
    labels:
      component: single_node_puma_workers
    expr: '0.85'
  - record: slo:max:hard:gitlab_component_saturation:ratio
    labels:
      component: single_node_puma_workers
    expr: '0.9'
- name: GitLab Saturation Alerts
  interval: 1m
  rules:
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Cgroup Memory Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Cgroup Memory Utilization per Node resource:

        Cgroup memory utilization per node.

        Some services, notably Gitaly, are configured to run within a cgroup with a memory limit lower than the memory limit for the node. This ensures that a traffic spike to Gitaly does not affect other services on the node.

        If this resource is becoming saturated, this may indicate traffic spikes to Gitaly, abuse or possibly resource leaks in the application. Gitaly or other git processes may be killed by the OOM killer when this resource is saturated.
      grafana_dashboard_id: alerts-sat_cgroup_memory
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_cgroup_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '96168'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                container_memory_usage_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_cache{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} -
                container_memory_swap{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              container_spec_memory_limit_bytes{id="/system.slice/gitlab-runsvdir.service", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="cgroup_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cgroup_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Average Service CPU Utilization resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average Service CPU Utilization resource:

        This resource measures average CPU utilization across an all cores in a service fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling.
      grafana_dashboard_id: alerts-sat_cpu
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_cpu?from=now-6h/m&to=now-1m/m&var-environment={{ $labels.environment
        }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '90152'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              1 - avg by (environment, tier, type, stage) (
                rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: >-
        The Disk inode Utilization per Device per Node resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk inode Utilization per Device per Node resource:

        Disk inode utilization per device per node.

        If this is too high, its possible that a directory is filling up with files. Consider logging in an checking temp directories for large numbers of files
      grafana_dashboard_id: alerts-sat_disk_inodes
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_disk_inodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '24424'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              1 - (
                node_filesystem_files_free{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                node_filesystem_files{fstype=~"(ext.|xfs)", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 15m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 15m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="disk_inodes"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_inodes"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Disk Space Utilization per Device per Node resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Space Utilization per Device per Node resource:

        Disk space utilization per device per node.
      grafana_dashboard_id: alerts-sat_disk_space
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '2632'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              (
                1 - instance:node_filesystem_avail:ratio{fstype=~"ext.|xfs", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: >-
        The Disk Sustained Read IOPS Utilization per Node resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Read IOPS Utilization per Node resource:

        Disk sustained read IOPS utilization per node.
      grafana_dashboard_id: alerts-sat_disk_sus_read_iops
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_disk_sus_read_iops?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '69768'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_reads_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 25m
      alert_type: cause
      bound: upper
      burn_rate_period: 20m
      metric: gitlab_component_saturation:ratio
      period: 25m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_read_iops"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_read_iops"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: >-
        The Disk Sustained Read Throughput Utilization per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Read Throughput Utilization per Node resource:

        Disk sustained read throughput utilization per node.
      grafana_dashboard_id: alerts-sat_disk_sus_read_throughput
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_disk_sus_read_throughput?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '66056'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_read_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_read_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 25m
      alert_type: cause
      bound: upper
      burn_rate_period: 20m
      metric: gitlab_component_saturation:ratio
      period: 25m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_read_throughput"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_read_throughput"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: >-
        The Disk Sustained Write IOPS Utilization per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Write IOPS Utilization per Node resource:

        Gitaly runs on Google Cloud's Persistent Disk product. This has a published sustained maximum write IOPS value. This value can be exceeded for brief periods.

        If a single node is consistently reaching saturation, it may indicate a noisy-neighbour repository, possible abuse or it may indicate that the node needs rebalancing.

        More information can be found at https://cloud.google.com/compute/docs/disks/performance.
      grafana_dashboard_id: alerts-sat_disk_sus_write_iops
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_disk_sus_write_iops?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '15048'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_writes_completed_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_iops{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 25m
      alert_type: cause
      bound: upper
      burn_rate_period: 20m
      metric: gitlab_component_saturation:ratio
      period: 25m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_write_iops"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_write_iops"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: >-
        The Disk Sustained Write Throughput Utilization per Node resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Sustained Write Throughput Utilization per Node resource:

        Gitaly runs on Google Cloud's Persistent Disk product. This has a published sustained maximum write throughput value. This value can be exceeded for brief periods.

        If a single node is consistently reaching saturation, it may indicate a noisy-neighbour repository, possible abuse or it may indicate that the node needs rebalancing.

        More information can be found at https://cloud.google.com/compute/docs/disks/performance.
      grafana_dashboard_id: alerts-sat_disk_sus_write_throughput
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_disk_sus_write_throughput?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '16648'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, device) (
          clamp_min(
            clamp_max(
              rate(node_disk_written_bytes_total{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[20m])
              /
              node_disk_max_write_bytes_seconds{device!="sda", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 25m
      alert_type: cause
      bound: upper
      burn_rate_period: 20m
      metric: gitlab_component_saturation:ratio
      period: 25m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="disk_sustained_write_throughput"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="disk_sustained_write_throughput"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Average CPU Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU utilization per Node.

        This resource measures all CPU across a fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling. The metrics are coming from elasticsearch_exporter.
      grafana_dashboard_id: alerts-sat_elastic_cpu
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_elastic_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '4200'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              avg by (environment, tier, type, stage) (
                avg_over_time(elasticsearch_process_cpu_percent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m]) / 100
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Disk Utilization Overall resource of the {{ $labels.type }} service ({{ $labels.stage }} stage),
        component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Utilization Overall resource:

        Disk utilization per device per node.
      grafana_dashboard_id: alerts-sat_elastic_disk_space
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_elastic_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '18024'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage) (
                (elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} - elasticsearch_filesystem_data_free_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"})
              )
              /
              sum by (environment, tier, type, stage) (
                elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="elastic_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The JVM Heap Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the JVM Heap Utilization per Node resource:

        JVM heap memory utilization per node.
      grafana_dashboard_id: alerts-sat_elastic_jvm_heap_memory
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_elastic_jvm_heap_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '18568'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name) (
          clamp_min(
            clamp_max(
              elasticsearch_jvm_memory_used_bytes{area="heap", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              /
              elasticsearch_jvm_memory_max_bytes{area="heap", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_jvm_heap_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_jvm_heap_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Average CPU Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU per Node.

        This resource measures all CPU across a fleet. If it is becoming saturated, it may indicate that the fleet needs horizontal or vertical scaling. The metrics are coming from elasticsearch_exporter.
      grafana_dashboard_id: alerts-sat_elastic_single_node_cpu
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_elastic_single_node_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '31080'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name) (
          clamp_min(
            clamp_max(
              avg_over_time(elasticsearch_process_cpu_percent{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) / 100
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_single_node_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_single_node_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Disk Utilization per Device per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Disk Utilization per Device per Node resource:

        Disk utilization per device per node.
      grafana_dashboard_id: alerts-sat_elastic_node_disk_space
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_elastic_node_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '58504'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name) (
          clamp_min(
            clamp_max(
              (
                (
                  elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                  -
                  elasticsearch_filesystem_data_free_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                )
                /
                elasticsearch_filesystem_data_size_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_single_node_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_single_node_disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Thread pool utilization resource of the {{ $labels.type }} service ({{ $labels.stage }} stage),
        component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Thread pool utilization resource:

        Utilization of each thread pool on each node.

        Descriptions of the threadpool types can be found at https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html.
      grafana_dashboard_id: alerts-sat_elastic_thread_pools
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_elastic_thread_pools?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '2728'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, name, exported_type) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(elasticsearch_thread_pool_active_count{exported_type!="snapshot", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                /
                (avg_over_time(elasticsearch_thread_pool_threads_count{exported_type!="snapshot", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) > 0)
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="elastic_thread_pools"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="elastic_thread_pools"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Go Memory Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Go Memory Utilization per Node resource:

        Go's memory allocation strategy can make it look like a Go process is saturating memory when measured using RSS, when in fact the process is not at risk of memory saturation. For this reason, we measure Go processes using the `go_memstat_alloc_bytes` metric instead of RSS.
      grafana_dashboard_id: alerts-sat_go_memory
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_go_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '45864'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, fqdn) (
                go_memstats_alloc_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              /
              sum by (environment, tier, type, stage, fqdn) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="go_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="go_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 25m
    annotations:
      title: >-
        The HPA Instances resource of the {{ $labels.type }} service ({{ $labels.stage }} stage), component
        has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the HPA Instances resource:

        This measures the HPA that manages our Deployments. If we are running low on ability to scale up by hitting our maximum HPA Pod allowance, we will have fully saturated this service.
      grafana_dashboard_id: alerts-sat_kube_hpa_instances
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_kube_hpa_instances?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '7528'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, hpa) (
          clamp_min(
            clamp_max(
              label_replace(
                label_replace(
                  kube_hpa_status_desired_replicas{environment="{{ $labels.environment }}", hpa!~"gitlab-sidekiq-(database-throttled|elasticsearch|gitaly-throttled|memory-bound|urgent-other)-v1"}
                  /
                  kube_hpa_spec_max_replicas,
                  "stage", "cny", "hpa", "gitlab-cny-.*"
                ),
                "type", "$1", "hpa", "gitlab-(?:cny-)?(\\w+)"
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 25m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 25m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="kube_hpa_instances"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_hpa_instances"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Kube Persistent Volume Claim inode Utilisation resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Persistent Volume Claim inode Utilisation resource:

        disk space utilization on persistent volume claims.
      grafana_dashboard_id: alerts-sat_kube_pvc_disk_space
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_kube_pvc_disk_space?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '15240'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, persistentvolumeclaim) (
          clamp_min(
            clamp_max(
              kubelet_volume_stats_used_bytes
              /
              kubelet_volume_stats_capacity_bytes
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_disk_space"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_disk_space"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Kube Persistent Volume Claim inode Utilisation resource of the {{ $labels.type }} service
        ({{ $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Kube Persistent Volume Claim inode Utilisation resource:

        inode utilization on persistent volume claims.
      grafana_dashboard_id: alerts-sat_kube_pvc_inodes
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_kube_pvc_inodes?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '6952'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, persistentvolumeclaim) (
          clamp_min(
            clamp_max(
              kubelet_volume_stats_inodes_used
              /
              kubelet_volume_stats_inodes
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_inodes"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="kube_persistent_volume_claim_inodes"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Memory Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage }}
        stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Memory Utilization per Node resource:

        Memory utilization per device per node.
      grafana_dashboard_id: alerts-sat_memory
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '42024'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              instance:node_memory_utilization:ratio{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Open file descriptor utilization per instance resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Open file descriptor utilization per instance resource:

        Open file descriptor utilization per instance.

        Saturation on file descriptor limits may indicate a resource-descriptor leak in the application.

        As a temporary fix, you may want to consider restarting the affected process.
      grafana_dashboard_id: alerts-sat_open_fds
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_open_fds?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '54344'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, job, instance) (
          clamp_min(
            clamp_max(
              (
                process_open_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              or
              (
                ruby_file_descriptors{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
                /
                ruby_process_max_fds{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="open_fds"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="open_fds"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Active Primary DB Connection Utilization resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Active Primary DB Connection Utilization resource:

        Active db connection utilization on the primary node.

        Postgres is configured to use a maximum number of connections. When this resource is saturated, connections may queue.
      grafana_dashboard_id: alerts-sat_active_db_connections_primary
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_active_db_connections_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '62920'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum without (state) (
                pg_stat_activity_count{datname="gitlabhq_production", state!="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} unless on(instance) (pg_replication_is_replica == 1)
              )
              / on (environment, tier, type, stage, fqdn)
              pg_settings_max_connections{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pg_active_db_connections_primary"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_active_db_connections_primary"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Active Secondary DB Connection Utilization resource of the {{ $labels.type }} service ({{
        $labels.stage }} stage), component has a saturation exceeding SLO and is close to its capacity
        limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Active Secondary DB Connection Utilization resource:

        Active db connection utilization per replica node

        Postgres is configured to use a maximum number of connections. When this resource is saturated, connections may queue.
      grafana_dashboard_id: alerts-sat_active_db_connections_replica
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_active_db_connections_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '93992'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum without (state) (
                pg_stat_activity_count{datname="gitlabhq_production", state!="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"} and on(instance) (pg_replication_is_replica == 1)
              )
              / on (environment, tier, type, stage, fqdn)
              pg_settings_max_connections{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pg_active_db_connections_replica"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pg_active_db_connections_replica"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: >-
        The Postgres Async (Sidekiq) primary Connection Pool Utilization per Node resource of the {{ $labels.type
        }} service ({{ $labels.stage }} stage), component has a saturation exceeding SLO and is close
        to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Async (Sidekiq) primary Connection Pool Utilization per Node resource:

        pgbouncer async connection pool utilization per database node, for primary database connections.

        Sidekiq maintains it's own pgbouncer connection pool. When this resource is saturated, database operations may queue, leading to additional latency in background processing.
      grafana_dashboard_id: alerts-sat_pgbouncer_async_pool_primary
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_async_pool_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '50632'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production_sidekiq", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 10m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 10m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_async_primary_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_async_primary_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The PGBouncer Single Core per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the PGBouncer Single Core per Node resource:

        PGBouncer single core CPU utilization per node.

        PGBouncer is a single threaded application. Under high volumes this resource may become saturated, and additional pgbouncer nodes may need to be provisioned.
      grafana_dashboard_id: alerts-sat_pgbouncer_single_core
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_single_core?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '98120'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, groupname) (
          clamp_min(
            clamp_max(
              sum without(cpu, mode) (
                rate(
                  namedprocess_namegroup_cpu_seconds_total{groupname=~"pgbouncer.*", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m]
                )
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_single_core"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_single_core"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: >-
        The Postgres Sync (Web/API/Git) primary Connection Pool Utilization per Node resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage), component has a saturation exceeding SLO
        and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Sync (Web/API/Git) primary Connection Pool Utilization per Node resource:

        pgbouncer sync connection pool Saturation per database node, for primary database connections.

        Web/api/git applications use a separate connection pool to sidekiq.

        When this resource is saturated, web/api database operations may queue, leading to unicorn/puma saturation and 503 errors in the web.
      grafana_dashboard_id: alerts-sat_pgbouncer_sync_pool_primary
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_sync_pool_primary?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '56488'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 10m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 10m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_sync_primary_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_sync_primary_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: >-
        The Postgres Sync (Web/API/Git) replica Connection Pool Utilization per Node resource of the {{
        $labels.type }} service ({{ $labels.stage }} stage), component has a saturation exceeding SLO
        and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Postgres Sync (Web/API/Git) replica Connection Pool Utilization per Node resource:

        pgbouncer sync connection pool Saturation per database node, for replica database connections.

        Web/api/git applications use a separate connection pool to sidekiq.

        When this resource is saturated, web/api database operations may queue, leading to unicorn/puma saturation and 503 errors in the web.
      grafana_dashboard_id: alerts-sat_pgbouncer_sync_pool_replica
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_pgbouncer_sync_pool_replica?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '22312'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, instance) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(pgbouncer_pools_server_active_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_testing_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_used_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]) +
                avg_over_time(pgbouncer_pools_server_login_connections{user="gitlab", database="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              / on(environment, tier, type, stage, fqdn, instance) group_left()
              sum by (environment, tier, type, stage, fqdn, instance) (
                avg_over_time(pgbouncer_databases_pool_size{name="gitlabhq_production", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 10m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 10m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="pgbouncer_sync_replica_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="pgbouncer_sync_replica_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Private Runners utilization resource of the {{ $labels.type }} service ({{ $labels.stage }}
        stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Private Runners utilization resource:

        Private runners utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_private_runners
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_private_runners?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '12488'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state) (max_over_time(gitlab_runner_jobs{job="private-runners"}[1m]))
              /
              gitlab_runner_limit{job="private-runners"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="private_runners"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="private_runners"}
  - alert: component_saturation_slo_out_of_bounds
    for: 15m
    annotations:
      title: >-
        The Rails DB Connection Pool Utilization resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Rails DB Connection Pool Utilization resource:

        Rails uses connection pools for its database connections. As each node may have multiple connection pools, this is by node and by database host.

        If this resource is saturated, it may indicate that our connection pools are not correctly sized, perhaps because an unexpected application thread is using a database connection.
      grafana_dashboard_id: alerts-sat_rails_db_connection_pool
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_rails_db_connection_pool?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '2952'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn, host, port) (
          clamp_min(
            clamp_max(
              (
                avg_over_time(gitlab_database_connection_pool_busy{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
                +
                avg_over_time(gitlab_database_connection_pool_dead{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              /
              gitlab_database_connection_pool_size{class="ActiveRecord::Base", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 15m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 15m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="rails_db_connection_pool"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="rails_db_connection_pool"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Redis Client Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Client Utilization per Node resource:

        Redis client utilization per node.

        A redis server has a maximum number of clients that can connect. When this resource is saturated, new clients may fail to connect.

        More details at https://redis.io/topics/clients#maximum-number-of-clients
      grafana_dashboard_id: alerts-sat_redis_clients
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_redis_clients?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '29992'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max_over_time(redis_connected_clients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              /
              redis_config_maxclients{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="redis_clients"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_clients"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Redis Memory Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Memory Utilization per Node resource:

        Redis memory utilization per node.

        As Redis memory saturates node memory, the likelyhood of OOM kills, possibly to the Redis process, become more likely.

        For caches, consider lowering the `maxmemory` setting in Redis. For non-caching Redis instances, this has been caused in the past by credential stuffing, leading to large numbers of web sessions.
      grafana_dashboard_id: alerts-sat_redis_memory
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_redis_memory?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '25192'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              max by (environment, tier, type, stage, fqdn) (
                label_replace(redis_memory_used_rss_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "rss","","")
                or
                label_replace(redis_memory_used_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}, "memtype", "used","","")
              )
              /
              avg by (environment, tier, type, stage, fqdn) (
                node_memory_MemTotal_bytes{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="redis_memory"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_memory"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Redis Primary CPU Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Primary CPU Utilization per Node resource:

        Redis Primary CPU Utilization per Node.

        Redis is single-threaded. A single Redis server is only able to scale as far as a single CPU on a single host. When the primary Redis service is saturated, major slowdowns should be expected across the application, so avoid if at all possible.
      grafana_dashboard_id: alerts-sat_redis_primary_cpu
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_redis_primary_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '2056'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                rate(redis_cpu_user_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
                +
                rate(redis_cpu_sys_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              )
              and on (instance) redis_instance_info{role="master"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s1
    expr: |
      gitlab_component_saturation:ratio{component="redis_primary_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_primary_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Redis Secondary CPU Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Redis Secondary CPU Utilization per Node resource:

        Redis Secondary CPU Utilization per Node.

        Redis is single-threaded. A single Redis server is only able to scale as far as a single CPU on a single host. CPU saturation on a secondary is not as serious as critical as saturation on a primary, but could lead to replication delays.
      grafana_dashboard_id: alerts-sat_redis_secondary_cpu
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_redis_secondary_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '20520'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              (
                rate(redis_cpu_user_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
                +
                rate(redis_cpu_sys_seconds_total{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m])
              )
              and on (instance) redis_instance_info{role!="master"}
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="redis_secondary_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="redis_secondary_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Average CPU Utilization per Shard resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Shard resource:

        This resource measures average CPU utilization across an all cores in a shard of a service fleet. If it is becoming saturated, it may indicate that the shard needs horizontal or vertical scaling.
      grafana_dashboard_id: alerts-sat_shard_cpu
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_shard_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '69096'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, shard) (
          clamp_min(
            clamp_max(
              1 - avg by (environment, tier, type, stage, shard) (
                rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s3
    expr: |
      gitlab_component_saturation:ratio{component="shard_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shard_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Shared Runner utilization resource of the {{ $labels.type }} service ({{ $labels.stage }}
        stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Shared Runner utilization resource:

        Shared runner utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_shared_runners
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_shared_runners?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '25128'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state) (max_over_time(gitlab_runner_jobs{job="shared-runners"}[1m]))
              /
              gitlab_runner_limit{job="shared-runners"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="shared_runners"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shared_runners"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Shared Runner GitLab Utilization resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Shared Runner GitLab Utilization resource:

        Shared runners utilization per instance.

        Each runner manager has a maximum number of runners that it can coordinate at any single moment.

        When this metric is saturated, new CI jobs will queue. When this occurs we should consider adding more runner managers, or scaling the runner managers vertically and increasing their maximum runner capacity.
      grafana_dashboard_id: alerts-sat_shared_runners_gitlab
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_shared_runners_gitlab?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '75400'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, instance) (
          clamp_min(
            clamp_max(
              sum without(executor_stage, exported_stage, state) (max_over_time(gitlab_runner_jobs{job="shared-runners-gitlab-org"}[1m]))
              /
              gitlab_runner_limit{job="shared-runners-gitlab-org"} > 0
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="shared_runners_gitlab"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="shared_runners_gitlab"}
  - alert: component_saturation_slo_out_of_bounds
    for: 10m
    annotations:
      title: >-
        The Sidekiq Worker Utilization per shard resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Sidekiq Worker Utilization per shard resource:

        Sidekiq worker utilization per shard.

        This metric represents the percentage of available threads*workers that are actively processing jobs.

        When this metric is saturated, new Sidekiq jobs will queue. Depending on whether or not the jobs are latency sensitive, this could impact user experience.
      grafana_dashboard_id: alerts-sat_sidekiq_shard_workers
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_sidekiq_shard_workers?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '10536'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, shard) (
          clamp_min(
            clamp_max(
              sum by (environment, tier, type, stage, shard) (
                avg_over_time(sidekiq_running_jobs{shard!~"database-throttled|elasticsearch|gitaly-throttled|memory-bound", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              /
              sum by (environment, tier, type, stage, shard) (
                avg_over_time(sidekiq_concurrency{shard!~"database-throttled|elasticsearch|gitaly-throttled|memory-bound", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m])
              )
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 10m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 10m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="sidekiq_shard_workers"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="sidekiq_shard_workers"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Average CPU Utilization per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Average CPU Utilization per Node resource:

        Average CPU utilization per Node.

        If average CPU is satured, it may indicate that a fleet is in need to horizontal or vertical scaling. It may also indicate imbalances in load in a fleet.
      grafana_dashboard_id: alerts-sat_single_node_cpu
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_single_node_cpu?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '57960'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              avg without(cpu, mode) (1 - rate(node_cpu_seconds_total{mode="idle", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[5m]))
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 5m
      metric: gitlab_component_saturation:ratio
      period: 5m
      rules_domain: general
      severity: s4
    expr: |
      gitlab_component_saturation:ratio{component="single_node_cpu"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="single_node_cpu"}
  - alert: component_saturation_slo_out_of_bounds
    for: 5m
    annotations:
      title: >-
        The Puma Worker Saturation per Node resource of the {{ $labels.type }} service ({{ $labels.stage
        }} stage), component has a saturation exceeding SLO and is close to its capacity limit.
      description: |
        This means that this resource is running close to capacity and is at risk of exceeding its current capacity limit.

        Details of the Puma Worker Saturation per Node resource:

        Puma thread utilization per node.

        Puma uses a fixed size thread pool to handle HTTP requests. This metric shows how many threads are busy handling requests. When this resource is saturated, we will see puma queuing taking place. Leading to slowdowns across the application.

        Puma saturation is usually caused by latency problems in downstream services: usually Gitaly or Postgres, but possibly also Redis. Puma saturation can also be caused by traffic spikes.
      grafana_dashboard_id: alerts-sat_single_node_puma_workers
      grafana_dashboard_link: >-
        https://dashboards.gitlab.net/d/alerts-sat_single_node_puma_workers?from=now-6h/m&to=now-1m/m&var-environment={{
        $labels.environment }}&var-type={{ $labels.type }}&var-stage={{ $labels.stage }}
      grafana_min_zoom_hours: '6'
      grafana_panel_id: '71272'
      grafana_variables: environment,type,stage
      promql_query: |
        max by(environment, tier, type, stage, fqdn) (
          clamp_min(
            clamp_max(
              sum by(environment, tier, type, stage, fqdn) (avg_over_time(puma_active_connections{environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"}[1m]))
              /
              sum by(environment, tier, type, stage, fqdn) (puma_max_threads{pid="puma_master", environment="{{ $labels.environment }}",stage="{{ $labels.stage }}",type="{{ $labels.type }}"})
              ,
              1)
          ,
          0)
        )
      runbook: docs/{{ $labels.type }}/service-{{ $labels.type }}.md
    labels:
      alert_trigger_duration: 5m
      alert_type: cause
      bound: upper
      burn_rate_period: 1m
      metric: gitlab_component_saturation:ratio
      pager: pagerduty
      period: 5m
      rules_domain: general
      severity: s2
    expr: |
      gitlab_component_saturation:ratio{component="single_node_puma_workers"} > on(component) group_left
      slo:max:hard:gitlab_component_saturation:ratio{component="single_node_puma_workers"}
